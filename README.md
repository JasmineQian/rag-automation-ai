# Agentic AI RAG æµ‹è¯•å¹³å°

ä¸€ä¸ªåŸºäº RAG (Retrieval-Augmented Generation) æ¶æ„çš„ Agentic AI æµ‹è¯•å¹³å°ï¼Œæ—¨åœ¨æä¾›ä¸€ä¸ªæœ¬åœ°ã€å¯æ§çš„ç¯å¢ƒï¼Œç”¨äºæµ‹è¯•å’Œè°ƒè¯• AI Agent çš„çŸ¥è¯†è·å–ä¸å†³ç­–èƒ½åŠ›ã€‚

è¯¥å¹³å°é›†æˆäº† Streamlit å¯è§†åŒ–ç•Œé¢ã€åŸºäºæœ¬åœ°å¤§è¯­è¨€æ¨¡å‹ï¼ˆé€šè¿‡ Ollamaï¼‰çš„ Agent ä»¥åŠä¸€ä¸ªç”±æœ¬åœ°æ–‡æ¡£æ„å»ºçš„çŸ¥è¯†åº“ã€‚

## âœ¨ åŠŸèƒ½ç‰¹æ€§

- ğŸ§  **RAG é›†æˆ**ï¼šAgent çš„å›ç­”ç”±å…¶ä»æœ¬åœ°çŸ¥è¯†åº“ä¸­æ£€ç´¢åˆ°çš„ä¿¡æ¯å¢å¼ºï¼Œæ¨¡æ‹ŸçœŸå®ä¸–ç•Œä¸­çš„çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ã€‚
- ğŸ” **å¯è§†åŒ–è°ƒè¯•é¢æ¿**ï¼šåœ¨èŠå¤©ç•Œé¢ä¸­ï¼Œæ¸…æ™°åœ°å±•ç¤ºç”¨æˆ·è¾“å…¥ã€æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä»¥åŠ Agent çš„æœ€ç»ˆè¾“å‡ºï¼Œä¾¿äºåˆ†æå’Œè°ƒè¯•ã€‚
- ğŸ  **å®Œå…¨æœ¬åœ°åŒ–**ï¼šä½¿ç”¨ Ollama åœ¨æœ¬åœ°è¿è¡Œ Llama 3 ç­‰å¤§è¯­è¨€æ¨¡å‹ï¼Œç¡®ä¿æ•°æ®éšç§å’Œå®‰å…¨ã€‚
- ğŸ”§ **åŠ¨æ€çŸ¥è¯†åº“**ï¼šåŸºäºæœ¬åœ°æ–‡ä»¶ï¼ˆä¾‹å¦‚ `examples/sample_features.txt`ï¼‰æ„å»ºå‘é‡çŸ¥è¯†åº“ï¼Œæ˜“äºæ‰©å±•å’Œå®šåˆ¶ã€‚
- ğŸ’¬ **äº¤äº’å¼ Agent ç•Œé¢**ï¼šé€šè¿‡ Streamlit æä¾›å‹å¥½çš„èŠå¤©ç•Œé¢ï¼Œä¸ AI Agent è¿›è¡Œå®æ—¶äº¤äº’ã€‚

## ğŸ›ï¸ ç³»ç»Ÿæ¶æ„

```
+--------------------------------+
|  Streamlit Web UI              |
|  (Chat, Context Visualization) |
+----------------+---------------+
                 |
                 v
+----------------+---------------+
|  TestAgent                     |  â† æ ¸å¿ƒ Agent é€»è¾‘
+----------------+---------------+
                 |
                 v
+----------------+---------------+
|  RAG Module (Retriever)        |  â† FAISS å‘é‡çŸ¥è¯†åº“
+----------------+---------------+
                 |
                 v
+--------------------------------+
|  Ollama (LLM Backend)          |  â† æœ¬åœ°è¿è¡Œ Llama 3
+--------------------------------+
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡ç¯å¢ƒï¼šOllama å’Œå¤§è¯­è¨€æ¨¡å‹

ç¡®ä¿æ‚¨å·²åœ¨æœ¬åœ°å®‰è£…äº† Ollamaï¼Œå¹¶æ‹‰å–äº†æ‰€éœ€çš„è¯­è¨€æ¨¡å‹ã€‚

```bash
# è®¿é—® ollama.com å®‰è£… Ollama

# æ‹‰å– Llama 3 æ¨¡å‹
ollama pull llama3
```
*è¯¥é¡¹ç›®é»˜è®¤ä½¿ç”¨ `llama3`ï¼Œæ‚¨å¯ä»¥åœ¨ `src/config/settings.py` ä¸­ä¿®æ”¹é…ç½®ã€‚*

### 2. è®¾ç½®é¡¹ç›®

å…‹éš†é¡¹ç›®åï¼Œåˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…ä¾èµ–ã€‚

```bash
# åˆ›å»ºå¹¶æ¿€æ´» Python è™šæ‹Ÿç¯å¢ƒ & å®‰è£…é¡¹ç›®ä¾èµ–
python -m venv .venv
source .venv/bin/activate
pip upgrade install pip
pip install -r requirements.txt
```

### 3. é…ç½®ç¯å¢ƒå˜é‡

é¡¹ç›®éœ€è¦ä¸€ä¸ªç¯å¢ƒå˜é‡æ–‡ä»¶æ¥é…ç½® Ollama å’Œå…¶ä»–è®¾ç½®ã€‚

å¤åˆ¶ `config.env.example`ï¼ˆå¦‚æœå­˜åœ¨ï¼‰æˆ–æ‰‹åŠ¨åˆ›å»ºä¸€ä¸ªåä¸º `config.env` çš„æ–‡ä»¶ï¼Œå¹¶å¡«å…¥ä»¥ä¸‹å†…å®¹ï¼š

```env
# Ollama é…ç½®
OLLAMA_BASE_URL=http://localhost:11434
LLAMA_MODEL=llama3

# Google API Key (å½“å‰ Web UI å¯åŠ¨æ—¶éœ€è¦)
GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY"
```
> **æ³¨æ„**: å³ä½¿æˆ‘ä»¬ä¸»è¦ä¾èµ–æœ¬åœ°çš„ Ollamaï¼Œ`src/web/app.py` ä¸­ä¿ç•™äº†å¯¹ `GOOGLE_API_KEY` çš„æ£€æŸ¥ã€‚æ‚¨å¯ä»¥æš‚æ—¶å¡«å…¥ä¸€ä¸ªä»»æ„å­—ç¬¦ä¸²ä»¥é€šè¿‡æ£€æŸ¥ã€‚

### 4. è¿è¡Œåº”ç”¨

å®Œæˆä»¥ä¸Šæ­¥éª¤åï¼Œä½¿ç”¨ Streamlit å¯åŠ¨ Web åº”ç”¨ã€‚

```bash
streamlit run src/web/app.py
```

åº”ç”¨å¯åŠ¨åï¼Œæµè§ˆå™¨å°†è‡ªåŠ¨æ‰“å¼€ Web ç•Œé¢ã€‚

## ğŸ’¡ ä½¿ç”¨æ–¹æ³•

1.  æ‰“å¼€ Web ç•Œé¢åï¼Œä»ä¾§è¾¹æ é€‰æ‹© **"ğŸ’¬ æ™ºèƒ½å¯¹è¯"** æ¨¡å¼ã€‚
2.  åœ¨åº•éƒ¨çš„èŠå¤©æ¡†ä¸­è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œä¾‹å¦‚ï¼š"ç”¨æˆ·ç™»å½•åŠŸèƒ½åº”è¯¥å¦‚ä½•æµ‹è¯•ï¼Ÿ"
3.  Agent ä¼šä½œå‡ºå›ç­”ã€‚å¦‚æœå›ç­”æ˜¯åŸºäºçŸ¥è¯†åº“çš„ï¼Œæ‚¨ä¼šçœ‹åˆ°ä¸€ä¸ªå¯å±•å¼€çš„ **"ğŸ” æŸ¥çœ‹æ£€ç´¢ä¸Šä¸‹æ–‡"** åŒºåŸŸï¼Œå…¶ä¸­åŒ…å«äº† Agent ç”¨æ¥ç”Ÿæˆç­”æ¡ˆçš„åŸå§‹ä¿¡æ¯ã€‚
4.  æ‚¨å¯ä»¥é€šè¿‡æŸ¥çœ‹ä¸Šä¸‹æ–‡æ¥è¯„ä¼° Agent çš„æ£€ç´¢å‡†ç¡®æ€§å’Œå›ç­”è´¨é‡ã€‚

## é¡¹ç›®ç»“æ„

```
rag-automation-ai/
â”œâ”€â”€ config.env                  # ç¯å¢ƒå˜é‡é…ç½®æ–‡ä»¶
â”œâ”€â”€ faiss_index/                # FAISS å‘é‡çŸ¥è¯†åº“ç›¸å…³æ–‡ä»¶
â”‚   â”œâ”€â”€ index.faiss
â”‚   â”œâ”€â”€ index.pkl
â”‚   â””â”€â”€ modern_segment_builder.txt
â”œâ”€â”€ main.py                     # å…¥å£è„šæœ¬ï¼ˆå¯é€‰ï¼‰
â”œâ”€â”€ README.md                   # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ README_LLAMA_SETUP.md       # LLaMA æ¨¡å‹å®‰è£…é…ç½®è¯´æ˜
â”œâ”€â”€ requirements.txt            # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ setup.py                    # å®‰è£…è„šæœ¬
â”œâ”€â”€ src/                        # æ ¸å¿ƒæºä»£ç 
â”‚   â”œâ”€â”€ agents/                 # Agent ç›¸å…³é€»è¾‘
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ test_agent.py
â”‚   â”œâ”€â”€ config/                 # é…ç½®ç›¸å…³
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”œâ”€â”€ generators/             # æµ‹è¯•ç”¨ä¾‹ä¸æ•°æ®ç”Ÿæˆå™¨
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_generator.py
â”‚   â”‚   â””â”€â”€ test_case_generator.py
â”‚   â”œâ”€â”€ rag/                    # RAG æ£€ç´¢ä¸çŸ¥è¯†åº“
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ knowledge_base.py
â”‚   â”‚   â””â”€â”€ retriever.py
â”‚   â”œâ”€â”€ utils/                  # å·¥å…·å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ helpers.py
â”‚   â”‚   â””â”€â”€ llama_client.py
â”‚   â””â”€â”€ web/                    # Web åº”ç”¨ï¼ˆStreamlitï¼‰
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ app.py
â”œâ”€â”€ Streamlit_vs_open-webui.md  # ç›¸å…³å¯¹æ¯”æ–‡æ¡£
â”œâ”€â”€ test_llama_integration.py   # Llama é›†æˆæµ‹è¯•è„šæœ¬
â””â”€â”€ requirement_bak.txt         # ä¾èµ–å¤‡ä»½
```

## ğŸ“– è¯¦ç»†ä½¿ç”¨æŒ‡å—

è¯·å‚é˜… [LLaMAæ¨¡å‹å®‰è£…å’Œé…ç½®æŒ‡å—](README_LLAMA_SETUP.md) äº†è§£å¦‚ä½•å®‰è£…å’Œé…ç½®LLaMAæ¨¡å‹ã€‚

## ğŸ”§ ç³»ç»Ÿè¦æ±‚

- Python 3.8+
- è‡³å°‘8GB RAMï¼ˆç”¨äºè¿è¡ŒLLaMA 2 7Bæ¨¡å‹ï¼‰
- 4GBå¯ç”¨ç£ç›˜ç©ºé—´ï¼ˆç”¨äºå­˜å‚¨æ¨¡å‹ï¼‰ 